{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sripada_CS6301.001_final_pro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTyogA-aBgZP",
        "colab_type": "code",
        "outputId": "6a4e3650-2b08-40c2-ebc5-89222eb626a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "# Install tpot on the server\n",
        "!pip install tpot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tpot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/c8/46f5c7231f8e3088052cda78ed36198f9ded9f5a5edfc99290f31aa6b57e/TPOT-0.10.1-py3-none-any.whl (74kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 5.3MB/s \n",
            "\u001b[?25hCollecting deap>=1.0 (from tpot)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/29/e7f2ecbe02997b16a768baed076f5fc4781d7057cd5d9adf7c94027845ba/deap-1.2.2.tar.gz (936kB)\n",
            "\u001b[K    100% |████████████████████████████████| 942kB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.16.2)\n",
            "Collecting update-checker>=0.16 (from tpot)\n",
            "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.20.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.2.1)\n",
            "Collecting stopit>=1.1.1 (from tpot)\n",
            "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.28.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.20.3)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->tpot) (2.21.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.2->tpot) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.2->tpot) (2.5.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.20.2->tpot) (1.12.0)\n",
            "Building wheels for collected packages: deap, stopit\n",
            "  Building wheel for deap (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/22/ea/bf/dc7c8a2262025a0ab5da9ef02282c198be88902791ca0c6658\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
            "Successfully built deap stopit\n",
            "Installing collected packages: deap, update-checker, stopit, tpot\n",
            "Successfully installed deap-1.2.2 stopit-1.1.2 tpot-0.10.1 update-checker-0.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKtouCrpbbWM",
        "colab_type": "text"
      },
      "source": [
        "https://colab.research.google.com/drive/1CIVn-GoOyY3H2_Bv8z09mkNRokQ9jlJ-#scrollTo=uhBlHuGpO2n6\n",
        "\n",
        "http://www.randalolson.com/2016/05/08/tpot-a-python-tool-for-automating-data-science/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsWrBQyjypfv",
        "colab_type": "text"
      },
      "source": [
        "below cell is not working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPGf4zFt6fP",
        "colab_type": "code",
        "outputId": "6ec7270a-53c1-4fb7-9fff-c5321230b572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#print(feature_data.head())\n",
        "\n",
        "'''\n",
        "X_trn = [ feature_data[i] for i in range(np.shape(feature_data)[0]) if feature_data[1]==0 ]\n",
        "print(X_trn.shape)\n",
        "y_trn = [ feature_data[i][-1] for i in range(np.shape(feature_data)[0]) if feature_data[1]==0 ]\n",
        "print(y_trn.shape)\n",
        "\n",
        "X_trn=np.where(feature_data[1]==0,feature_data)#[:,:-1]\n",
        "y_trn=np.where(feature_data[1]==0)[:,-1]\n",
        "print(X_trn.head())\n",
        "print(X_trn.shape)\n",
        "print(y_trn.shape)\n",
        "\n",
        "X_val = [ feature_data[i][:-1] for i in range(np.shape(Data)[0]) if (feature_data[1]==1 and feature_data[2]<=6) ]\n",
        "print(X_val.shape)\n",
        "y_val = [ feature_data[i][-1] for i in range(np.shape(Data)[0]) if (feature_data[1]==1 and feature_data[2]<=6) ]\n",
        "print(y_val.shape)\n",
        "\n",
        "X_val=np.where((feature_data[1]==1 and feature_data[2]<=6))[:,:-1]\n",
        "y_val=np.where((feature_data[1]==1 and feature_data[2]<=6))[:,-1]\n",
        "print(X_val.head())\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "X_tst = [ feature_data[i][:-1] for i in range(np.shape(Data)[0]) if (feature_data[1]==1 and feature_data[2]>6 and feature_data[2]<=12) ]\n",
        "print(X_trn.shape)\n",
        "y_tst = [ feature_data[i][-1] for i in range(np.shape(Data)[0]) if (feature_data[1]==1 and feature_data[2]>6 and feature_data[2]<=12) ]\n",
        "print(y_trn.shape)\n",
        "\n",
        "X_tst=np.where((feature_data[1]==1 and feature_data[2]>6 and feature_data[2]<=12))[:,:-1]\n",
        "y_tst=np.where((feature_data[1]==1 and feature_data[2]>6 and feature_data[2]<=12))[:,-1]\n",
        "print(X_trn.head())\n",
        "print(X_trn.shape)\n",
        "print(y_trn.shape)'''\n",
        "\n",
        "#another way which allso didn't work\n",
        "\n",
        "'''\n",
        "# pandas and numpy for data manipulation\n",
        "\n",
        "Data=pda.DataFrame(pda.read_csv('hour.csv'))\n",
        "feature_data=Data.iloc[:,2:]\n",
        "\n",
        "for i in range(feature_data.shape[0]):\n",
        "  if feature_data[1]==0:\n",
        "    X_trn[i] = feature_data[i,:-1]\n",
        "    y_trn[i] = feature_data[i,-1]\n",
        "  \n",
        "  elif feature_data[2]<=6:\n",
        "    X_val[i] = feature_data[i,:-1]\n",
        "    y_val[i] = feature_data[i,-1]\n",
        "    \n",
        "  else:#if feature_data[2]>6 and feature_data[2]<=12:\n",
        "    X_tst[i] = feature_data[i,:-1]\n",
        "    y_tst[i] = feature_data[i,-1]\n",
        "    \n",
        "print(X_trn.shape)\n",
        "print(y_val.shape)\n",
        "print(y_tst.head())'''\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# pandas and numpy for data manipulation\\n\\nData=pda.DataFrame(pda.read_csv('hour.csv'))\\nfeature_data=Data.iloc[:,2:]\\n\\nfor i in range(feature_data.shape[0]):\\n  if feature_data[1]==0:\\n    X_trn[i] = feature_data[i,:-1]\\n    y_trn[i] = feature_data[i,-1]\\n  \\n  elif feature_data[2]<=6:\\n    X_val[i] = feature_data[i,:-1]\\n    y_val[i] = feature_data[i,-1]\\n    \\n  else:#if feature_data[2]>6 and feature_data[2]<=12:\\n    X_tst[i] = feature_data[i,:-1]\\n    y_tst[i] = feature_data[i,-1]\\n    \\nprint(X_trn.shape)\\nprint(y_val.shape)\\nprint(y_tst.head())\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zaVKK7pcMok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to numpy arrays\n",
        "training_features = np.array(train_features)\n",
        "testing_features = np.array(test_features)\n",
        "\n",
        "# Sklearn wants the labels as one-dimensional vectors\n",
        "training_targets = np.array(train_labels).reshape((-1,))\n",
        "testing_targets = np.array(test_labels).reshape((-1,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nXrTyG4JbFq",
        "colab_type": "code",
        "outputId": "4585e57b-5df5-4f66-ed58-43be24b9b9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import pandas as pda\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from tpot import TPOTRegressor\n",
        "\n",
        "X_data=pda.read_csv('hour.csv',usecols=[2,4,5,6,7,8,9,10,11,12,13])\n",
        "y_data=pda.read_csv('hour.csv',usecols=[16])\n",
        "\n",
        "X_trn, X_eval, y_trn, y_eval = train_test_split(X_data, y_data, test_size=0.2)\n",
        "X_val, X_tst, y_val, y_tst = train_test_split(X_eval, y_eval, test_size=0.2)\n",
        "\n",
        "'''X_trn=Data.iloc[0:8685,2:-1]\n",
        "y_trn=Data.iloc[0:8685,-1]\n",
        "print(X_trn.head())\n",
        "X_val=Data.iloc[8685:13003,2:-1]\n",
        "y_val=Data.iloc[8685:13003,-1]\n",
        "X_tst=Data.iloc[13003:,2:-1]\n",
        "y_tst=Data.iloc[13003:,-1]'''\n",
        "print(X_trn.shape, y_trn.shape)\n",
        "print(X_tst.shape, y_tst.shape)\n",
        "print(X_val.shape, y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13903, 11) (13903, 1)\n",
            "(696, 11) (696, 1)\n",
            "(2780, 11) (2780, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1fr5nAkMSz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function that creates a column for every value it might have\n",
        "def CreateColumnPerValue(data, columnList):\n",
        "    for x in columnList:\n",
        "\n",
        "        values=pd.unique(data[x])\n",
        "        \n",
        "        for v in values:\n",
        "            column_name=x+\"_\"+str(v)   \n",
        "            data[column_name]=(data[x]==v).astype(float)\n",
        "    \n",
        "        data.drop(x, axis=1, inplace=True)\n",
        "      \n",
        "train_dataset = pd.get_dummies(train_dataset,columns =categorical_features)\n",
        "test_dataset = pd.get_dummies(test_dataset,columns =categorical_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgwj-vA4n3FT",
        "colab_type": "text"
      },
      "source": [
        "Gao's v and h stack for reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhrQG7kEn1X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pda\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "X=np.loadtxt(fname='hour.csv',delimiter=',',skiprows=1,usecols=(2,4,5,6,7,8,9,10,11,12,13))\n",
        "y=np.loadtxt(fname='hour.csv',delimiter=',',skiprows=1,usecols=16,dtype='int')\n",
        "n_half=math.floor(X.shape[0]/2)\n",
        "\n",
        "temp=np.vstack((np.roll(y,1), np.roll(y,2), np.roll(y,3), np.roll(y,4), np.roll(y,5), np.roll(y,6), \n",
        "                np.roll(y,7), np.roll(y,8), np.roll(y,9), np.roll(y,10),np.roll(y,11),np.roll(y,12)))\n",
        "X=np.hstack(( X, temp.T )); del temp\n",
        "X_trn=X[:n_half];y_trn=y[:n_half]\n",
        "X_val,X_tst,y_val,y_tst=train_test_split(X[n_half+1:],y[n_half+1:],test_size=0.4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oyDqzudc09z",
        "colab_type": "code",
        "outputId": "7638d656-63d1-4aee-eeb6-89d70921db04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#X = np.transpose([np.dot(X_trn,pca.components_[i]) for i in [0,1]])\n",
        "#X[0] = np.dot(X_trn,pca.components_[0].reshape(-1,1)\n",
        "#print(X.shape)\n",
        "\n",
        "# Fit the tpot model on the training data\n",
        "#tpot.fit(X_trn,y_trn)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.linear_model import LassoLarsCV\n",
        "from math import sqrt\n",
        "#from sklearn.pipeline import Pipeline\n",
        "\n",
        "RFRparam_grid = [{'max_depth': [2,5,10,15,20,25]}]\n",
        "rfr = GridSearchCV(RandomForestRegressor(random_state=0,n_estimators=500),RFRparam_grid, cv=5,scoring='neg_mean_squared_log_error')\n",
        "#y_pred_rfr_val = rfr.predict(X_val)\n",
        "\n",
        "for i in range(0,4):\n",
        "  rfr.fit(X_trn[i:,:11+i],y_trn[i:])\n",
        "  y_pred_rfr_val = rfr.predict(X_val[:, :11+i])\n",
        "  y_pred_rfr_val[ np.where(y_pred_rfr_val<0) ]=0\n",
        "  #y_pred_etr_val[y_pred_etr_val<0]=0\n",
        "  rfr_neg_preds=y_val.shape[0] - np.count_nonzero(y_pred_rfr_val)\n",
        "  print('RFR -ve predictions',rfr_neg_preds)\n",
        "  rfr_rmsle=sqrt(mean_squared_log_error(y_val,y_pred_rfr_val))\n",
        "  print('Root-mean-squared-log-error for ETR',rfr_rmsle)\n",
        "  #y_pred_rfr_val[y_pred_rfr_val<0] = 0\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RFR -ve predictions 0\n",
            "Root-mean-squared-log-error for ETR 0.5351277921391423\n",
            "RFR -ve predictions 0\n",
            "Root-mean-squared-log-error for ETR 0.3269084786188115\n",
            "RFR -ve predictions 0\n",
            "Root-mean-squared-log-error for ETR 0.3278302976146239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGzIaBkJmM9C",
        "colab_type": "text"
      },
      "source": [
        "ADAboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkkevhoQmPye",
        "colab_type": "code",
        "outputId": "0be489fa-d421-4b2e-e3c8-f826ab012fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "'''for i in range(y_val.shape[0]):\n",
        "  if y_pred_rfr_val[i]<0:\n",
        "    y_pred_rfr_val[i] = 0\n",
        "print(y_pred_rfr_val.shape)\n",
        "\n",
        "rfr_neg_preds=y_val.shape[0] - np.count_nonzero(y_pred_rfr_val)\n",
        "print('RF -ve prictions',rfr_neg_preds)\n",
        "rfr_rmsle=sqrt(mean_squared_log_error(y_val,y_pred_rfr_val))\n",
        "print('Root-mean-squared-log-error for RFR',rfr_rmsle)\n",
        "'''\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "ABRparam_grid = [{'learning_rate': [0.01,0.1,1,10]}]\n",
        "abr = GridSearchCV(AdaBoostRegressor(),ABRparam_grid, cv=8)#.fit(X_trn, y_trn)\n",
        "for i in range(0,15):\n",
        "  abr.fit(X_trn[i:,:11+i],y_trn[i:])\n",
        "  y_pred_abr_val = abr.predict(X_val[:, :11+i])\n",
        "  y_pred_abr_val[ np.where(y_pred_abr_val<0) ]=0\n",
        "  #y_pred_etr_val[y_pred_etr_val<0]=0\n",
        "  #abr_neg_preds=y_val.shape[0] - np.count_nonzero(y_pred_rfr_val)\n",
        "  #print('RFR -ve predictions',rfr_neg_preds)\n",
        "  abr_rmsle=sqrt(mean_squared_log_error(y_val,y_pred_abr_val))\n",
        "  print('Root-mean-squared-log-error for ABR',abr_rmsle)\n",
        "  #y_pred_rfr_val[y_pred_rfr_val<0] = 0\n",
        "\n",
        "  '''y_pred_abr_val = abr.predict(X_val)\n",
        "#y_pred_abr_val[y_pred_abr_val<0]=0\n",
        "for i in range(y_val.shape[0]):\n",
        "  if y_pred_abr_val[i]<0:\n",
        "    y_pred_abr_val[i] = 0\n",
        "print(y_pred_abr_val.shape)\n",
        "#y_pred_abr_val[y_pred_abr_val<0]=0\n",
        "abr_neg_preds=y_val.shape[0] - np.count_nonzero(y_pred_abr_val)\n",
        "print('AdaBoost -ve prictions',abr_neg_preds)\n",
        "abr_rmsle=sqrt(mean_squared_log_error(y_val,y_pred_abr_val))\n",
        "print('Root-mean-squared-log-error for ABR',abr_rmsle)\n",
        "\n",
        "\n",
        "\n",
        "y_pred_llr_val= LassoLarsCV().fit(X_trn,y_trn).predict(X_val)\n",
        "#y_pred_llr_val[y_pred_llr_val<0]=0\n",
        "for i in range(y_val.shape[0]):\n",
        "  if y_pred_llr_val[i]<0:\n",
        "    y_pred_llr_val[i] = 0\n",
        "print(y_pred_llr_val.shape)\n",
        "llr_neg_preds = y_val.shape[0] - np.count_nonzero(y_pred_llr_val)\n",
        "print('LLR -ve prictions',llr_neg_preds)\n",
        "llr_rmsle=sqrt(mean_squared_log_error(y_val,y_pred_llr_val))\n",
        "print('Root-mean-squared-log-error for LLR',llr_rmsle)\n",
        "\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Root-mean-squared-log-error for ABR 0.8764554959528335\n",
            "Root-mean-squared-log-error for ABR 0.6070125857533337\n",
            "Root-mean-squared-log-error for ABR 0.5976741227941524\n",
            "Root-mean-squared-log-error for ABR 0.5986493056679663\n",
            "Root-mean-squared-log-error for ABR 0.5993886423401656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Root-mean-squared-log-error for ABR 0.6014675656679238\n",
            "Root-mean-squared-log-error for ABR 0.5928821904290388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Root-mean-squared-log-error for ABR 0.5968376867702679\n",
            "Root-mean-squared-log-error for ABR 0.5970899773563022\n",
            "Root-mean-squared-log-error for ABR 0.594302878022036\n",
            "Root-mean-squared-log-error for ABR 0.5948200590208245\n",
            "Root-mean-squared-log-error for ABR 0.5955462535793721\n",
            "Root-mean-squared-log-error for ABR 0.5986573831340947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Root-mean-squared-log-error for ABR 0.5965588957316234\n",
            "Root-mean-squared-log-error for ABR 0.5973952819214187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYQhHgqWLOzD",
        "colab_type": "code",
        "outputId": "7748d74c-c3ab-4f66-8b54-3dcbb2451f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(rfr.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 15}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuEE8OTXdgkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "#y_test_pred = SVpipeline.predict(X_test_pred)\n",
        "#y_final=(y_test_pred).astype(np.int64)\n",
        "#print(y_final)\n",
        "np.savetxt('predictions.txt', tpot.predict(X_tst), fmt='%d', delimiter='\\n', encoding=None)\n",
        "\n",
        "#,y_tst))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4diGeG1LyJ9",
        "colab_type": "code",
        "outputId": "c310e573-2842-488d-cc1d-ece35dd9cc30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#from sklearn.metrics.pairwise import euclidean_distances as dist2\n",
        "#error = sum(abs(tpot.predict(X_tst) - y_tst))\n",
        "print(sum(abs(tpot.predict(X_tst) - y_tst)))\n",
        "print(sum(abs(tpot.predict(X_val) - y_val)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5093348793016048e-10\n",
            "1.4529177860822529e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-shM9XaUbIDX",
        "colab_type": "code",
        "outputId": "c082b38f-9cd0-46cb-9c93-80320db517dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor as ETR\n",
        "ETRparam_grid = [{'max_depth':[2,5,10,15,20,25]}]\n",
        "etr = GridSearchCV(ETR(n_estimators=500), ETRparam_grid, iid=False, cv=8,scoring='neg_mean_squared_log_error')\n",
        "\n",
        "#Bagpp=Pipeline([('Bag',BaggingRegressor(base_estimator=DecisionTreeRegressor(),n_estimators=100))])\n",
        "for i in range(0,10):\n",
        "  etr.fit(X_trn[i:,:11+i],y_trn[i:])\n",
        "  y_pred_etr_val = etr.predict(X_val[:, :11+i])\n",
        "  y_pred_etr_val[ np.where(y_pred_etr_val<0) ]=0\n",
        "  #y_pred_etr_val[y_pred_etr_val<0]=0\n",
        "  etr_neg_preds=y_val.shape[0] - np.count_nonzero(y_pred_etr_val)\n",
        "  print('ETR with',i,'time delays has',etr_neg_preds,' -ve predictions')\n",
        "  etr_rmsle=sqrt(mean_squared_log_error(y_val,y_pred_etr_val))\n",
        "  print('Root-mean-squared-log-error for ETR',etr_rmsle)\n",
        "  #print(\"dt={},ValErr={}\\n\".format(i,valErr))\n",
        "                    \n",
        "'''\n",
        "import xgboost \n",
        "from xgboost import XGBRegressor\n",
        "XGBRparam_grid = [{'gamma':[0,0.03,0.1,0.3], 'learning_rate':[0.1,0.07], 'max_depth':[2,5,10,15,20,25], 'n_estimators':[1000] , 'reg_alpha':[1e-5, 1e-2,  0.75], 'reg_lambda':[1e-5, 1e-2, 0.45]}]\n",
        "xgbr = GridSearchCV(XBGRegressor(), XGBRparam_grid, iid=False, cv=8,scoring='neg_mean_squared_log_error').fit(X_trn, y_trn)\n",
        "y_pred_xgbr_val = abr.predict(X_val)\n",
        "y_pred_xgbr_val[y_pred_xgbr_val<0]=0\n",
        "xgbr_neg_preds=y_val.shape[0] - np.count_nonzero(y_pred_xgbr_val)\n",
        "print('XGBoost -ve predictions',xgbr_neg_preds)\n",
        "xgbr_rmsle=sqrt(mean_squared_log_error(y_val,y_pred_xgbr_val))\n",
        "print('Root-mean-squared-log-error for XGBR',xgbr_rmsle)\n",
        "'''\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ETR with 0 time delays has 0  -ve predictions\n",
            "Root-mean-squared-log-error for ETR 0.5227179122515656\n",
            "ETR with 1 time delays has 0  -ve predictions\n",
            "Root-mean-squared-log-error for ETR 0.3435796679237422\n",
            "ETR with 2 time delays has 0  -ve predictions\n",
            "Root-mean-squared-log-error for ETR 0.34294684935845426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5c737417ad13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Bagpp=Pipeline([('Bag',BaggingRegressor(base_estimator=DecisionTreeRegressor(),n_estimators=100))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0metr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_trn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0my_pred_etr_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0my_pred_etr_val\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_etr_val\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m38cdw1RxDf",
        "colab_type": "code",
        "outputId": "3a3c56fc-6547-4580-f1cc-f80e47df41f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "! git clone https://github.com/pgmpy/pgmpy \n",
        "! cd pgmpy/\n",
        "! pip install -r requirements.txt\n",
        "! python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pgmpy'...\n",
            "remote: Enumerating objects: 13222, done.\u001b[K\n",
            "remote: Total 13222 (delta 0), reused 0 (delta 0), pack-reused 13222\u001b[K\n",
            "Receiving objects: 100% (13222/13222), 6.29 MiB | 24.77 MiB/s, done.\n",
            "Resolving deltas: 100% (9253/9253), done.\n",
            "\u001b[31mCould not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBXZJeQODFvM",
        "colab_type": "text"
      },
      "source": [
        "Below is Gao idea of using embedding to avoid data reshaping to 3 d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZHnJrUm1BsA",
        "colab_type": "code",
        "outputId": "b2b8e4c9-a8de-44c2-d39b-c4a102cb8a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        }
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as kr\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "ep=2\n",
        "\n",
        "X=np.loadtxt(fname='hour.csv',delimiter=',',skiprows=1,usecols=(2,4,5,6,7,8,9,10,11,12,13))\n",
        "y=np.loadtxt(fname='hour.csv',delimiter=',',skiprows=1,usecols=16,dtype='int')\n",
        "n_half=math.floor(X.shape[0]/1.1)\n",
        "\n",
        "X_trn=X[:n_half];y_trn=y[:n_half]\n",
        "X_val,X_tst,y_val,y_tst=train_test_split(X[n_half+1:],y[n_half+1:],test_size=0.2)\n",
        "'''\n",
        "X_trn_scaled = MinMaxScaler().fit_transform(X_trn)\n",
        "X_tst_scaled = MinMaxScaler().fit_transform(X_tst)\n",
        "y_trn_scaled = MinMaxScaler().fit_transform(y_trn.reshape((-1,1)))\n",
        "y_tst_scaled = MinMaxScaler().fit_transform(y_tst.reshape((-1,1)))\n",
        "X_val_scaled = MinMaxScaler().fit_transform(X_val)\n",
        "y_val_scaled = MinMaxScaler().fit_transform(y_val.reshape((-1,1)))\n",
        "'''\n",
        "lstm=kr.Sequential()\n",
        "#--I just added this:\n",
        "lstm.add(kr.layers.Embedding(11,output_dim=1000))\n",
        "#---------------------\n",
        "lstm.add(kr.layers.CuDNNLSTM(units=1000))\n",
        "lstm.add(kr.layers.Dense(units=1))\n",
        "\n",
        "opt=kr.optimizers.SGD()\n",
        "rmsle=kr.losses.MeanSquaredLogarithmicError()\n",
        "\n",
        "lstm.compile(loss=rmsle, optimizer=opt)#, metrics=['mean_squared_error'])\n",
        "'''\n",
        "path_checkpoint = '23_checkpoint.keras'\n",
        "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
        "                                      monitor='val_loss',\n",
        "                                      verbose=1,\n",
        "                                      save_weights_only=True,\n",
        "                                      save_best_only=True)\n",
        "\n",
        "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                                        patience=5, verbose=1)\n",
        "\n",
        "callback_tensorboard = TensorBoard(log_dir='./23_logs/',\n",
        "                                   histogram_freq=0,\n",
        "                                   write_graph=False)\n",
        "\n",
        "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                       factor=0.1,\n",
        "                                       min_lr=1e-4,\n",
        "                                       patience=0,\n",
        "                                       verbose=1)\n",
        "\n",
        "callbacks = [callback_early_stopping,\n",
        "             callback_checkpoint,\n",
        "             callback_tensorboard,\n",
        "             callback_reduce_lr]\n",
        "'''\n",
        "#for i in range(0,10):\n",
        "  #lstm.fit(X_trn[i:,:11+i],y_trn[i:], epochs=20, verbose=2, validation_data=(X_val,y_val), use_multiprocessing=True)\n",
        "#stm.fit(X_trn[3:,:14],y_trn[3:], epochs=7, verbose=2, validation_data=(X_val,y_val), use_multiprocessing=True)\n",
        "lstm.fit(X_trn,y_trn, epochs=17, verbose=2, validation_data=(X_val,y_val), use_multiprocessing=True)\n",
        "  \n",
        "y_pred_lstm_tst = lstm.predict(X_tst) #[:, :14])\n",
        "\n",
        "y_pred_lstm_tst[ np.where(y_pred_lstm_tst<0) ]=0\n",
        "  #y_pred_etr_val[y_pred_etr_val<0]=0\n",
        "lstm_neg_preds=y_tst.shape[0] - np.count_nonzero(y_pred_lstm_tst)\n",
        "print('LSTM with 3 time delays has',lstm_neg_preds,' -ve predictions')\n",
        "lstm_rmsle=math.sqrt(mean_squared_log_error(y_tst,y_pred_lstm_tst))\n",
        "print('Root-mean-squared-log-error for LSTM',lstm_rmsle)\n",
        "\n",
        "print(lstm.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15799 samples, validate on 1263 samples\n",
            "Epoch 1/17\n",
            " - 7s - loss: 3.0320 - val_loss: 2.0681\n",
            "Epoch 2/17\n",
            " - 5s - loss: 2.0328 - val_loss: 2.0143\n",
            "Epoch 3/17\n",
            " - 5s - loss: 2.0169 - val_loss: 2.0073\n",
            "Epoch 4/17\n",
            " - 5s - loss: 2.0154 - val_loss: 2.0061\n",
            "Epoch 5/17\n",
            " - 6s - loss: 2.0151 - val_loss: 2.0056\n",
            "Epoch 6/17\n",
            " - 6s - loss: 2.0151 - val_loss: 2.0055\n",
            "Epoch 7/17\n",
            " - 5s - loss: 2.0150 - val_loss: 2.0054\n",
            "Epoch 8/17\n",
            " - 5s - loss: 2.0149 - val_loss: 2.0055\n",
            "Epoch 9/17\n",
            " - 5s - loss: 2.0148 - val_loss: 2.0053\n",
            "Epoch 10/17\n",
            " - 5s - loss: 2.0148 - val_loss: 2.0055\n",
            "Epoch 11/17\n",
            " - 5s - loss: 2.0147 - val_loss: 2.0053\n",
            "Epoch 12/17\n",
            " - 5s - loss: 2.0147 - val_loss: 2.0051\n",
            "Epoch 13/17\n",
            " - 5s - loss: 2.0146 - val_loss: 2.0051\n",
            "Epoch 14/17\n",
            " - 5s - loss: 2.0146 - val_loss: 2.0052\n",
            "Epoch 15/17\n",
            " - 5s - loss: 2.0145 - val_loss: 2.0052\n",
            "Epoch 16/17\n",
            " - 5s - loss: 2.0144 - val_loss: 2.0050\n",
            "Epoch 17/17\n",
            " - 5s - loss: 2.0144 - val_loss: 2.0047\n",
            "LSTM with 3 time delays has 0  -ve predictions\n",
            "Root-mean-squared-log-error for LSTM 1.3562284124153778\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 1000)        11000     \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 1000)              8008000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1001      \n",
            "=================================================================\n",
            "Total params: 8,020,001\n",
            "Trainable params: 8,020,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uWXFgKf2Sh4",
        "colab_type": "code",
        "outputId": "1093fca1-969b-43bf-ece2-a810b0c5d6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#lstm.predict(X_test)\n",
        "result = lstm.evaluate(X_tst,y_tst) #x=np.expand_dims(X_tst, axis=0), y=np.expand_dims(y_tst, axis=0))\n",
        "\n",
        "print(\"loss (test-set):\", result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "316/316 [==============================] - 0s 112us/sample - loss: 1.8277\n",
            "loss (test-set): 1.827699765374389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoApPLuwC_01",
        "colab_type": "text"
      },
      "source": [
        "Below is Gao's new version without embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQrseoIZC8TO",
        "colab_type": "code",
        "outputId": "1551f41c-986e-41df-82d7-3e1738e070e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2392
        }
      },
      "source": [
        "# working RNN\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as kr\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def DataReshape(X,y):  \n",
        "#data Reshaped as X=(batch_size,timesteps,data_dim) y=(batch_size,data_dim)\n",
        "  \n",
        "  #X = MinMaxScaler().fit_transform(X)\n",
        "  X = np.reshape(X, (X.shape[0], X.shape[1], 1 ))\n",
        "  #y = MinMaxScaler().fit_transform(y.reshape((1,-1)))\n",
        "  y = np.reshape(y, (y.size, 1))\n",
        "  return X,y\n",
        "\n",
        "#X=np.loadtxt(fname='hour.csv',delimiter=',',skiprows=1,usecols=(2,4,5,6,7,8,9,10,11,12,13))\n",
        "y=np.loadtxt(fname='hour.csv',delimiter=',',skiprows=1,usecols=16,dtype='int')\n",
        "n_half=math.floor(y.shape[0]/2)\n",
        "\n",
        "temp=np.vstack((np.roll(y,1), np.roll(y,2), np.roll(y,3), np.roll(y,4), np.roll(y,5), np.roll(y,6), \n",
        "                np.roll(y,7), np.roll(y,8), np.roll(y,9), np.roll(y,10),np.roll(y,11),np.roll(y,12)))\n",
        "X=np.asarray(temp.T); del temp\n",
        "\n",
        "X_trn=X[:n_half];y_trn=y[:n_half]\n",
        "X_val,X_tst,y_val,y_tst=train_test_split(X[n_half+1:],y[n_half+1:],test_size=0.4)\n",
        "\n",
        "X_trn,y_trn=DataReshape(X_trn,y_trn)\n",
        "X_val,y_val=DataReshape(X_val,y_val)\n",
        "X_tst,y_tst=DataReshape(X_tst,y_tst)\n",
        "\n",
        "lstm=kr.Sequential()\n",
        "lstm.add(kr.layers.CuDNNLSTM(units=512,input_shape=(X_trn.shape[1],1)))\n",
        "lstm.add(kr.layers.Dense(units=1))\n",
        "\n",
        "opt=kr.optimizers.Adam()\n",
        "rmsle=kr.losses.MeanSquaredLogarithmicError()\n",
        "\n",
        "lstm.compile(loss=rmsle, optimizer=opt)\n",
        "\n",
        "lstm.fit(x=X_trn, y=y_trn, epochs=50, validation_data=(X_val,y_val), verbose=2, use_multiprocessing=True)\n",
        "print(lstm.summary())\n",
        "\n",
        "'''\n",
        "Here I just let it learn from y(t-i). Maybe we can try to let it learn from X(t-i)??\n",
        "\n",
        "I used MSLE to avoid errors. The ValErr need to be squared to get what we want.\n",
        "\n",
        "The result is not very well. We can try to improve it by increasing 'epochs'. Someone use epochs=100~500 for their RNN\n",
        "\n",
        "'''\n",
        "\n",
        "#lstm.fit(X_trn,y_trn, epochs=17, verbose=2, validation_data=(X_val,y_val), use_multiprocessing=True)\n",
        "  \n",
        "y_pred_lstm_tst = lstm.predict(X_tst) #[:, :14])\n",
        "\n",
        "y_pred_lstm_tst[ np.where(y_pred_lstm_tst<0) ]=0\n",
        "  #y_pred_etr_val[y_pred_etr_val<0]=0\n",
        "lstm_neg_preds=y_tst.shape[0] - np.count_nonzero(y_pred_lstm_tst)\n",
        "print('LSTM with 3 time delays has',lstm_neg_preds,' -ve predictions')\n",
        "lstm_rmsle=math.sqrt(mean_squared_log_error(y_tst,y_pred_lstm_tst))\n",
        "print('Root-mean-squared-log-error for LSTM',lstm_rmsle)\n",
        "\n",
        "print(lstm.summary())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8689 samples, validate on 5213 samples\n",
            "Epoch 1/50\n",
            " - 3s - loss: 2.1795 - val_loss: 1.7167\n",
            "Epoch 2/50\n",
            " - 2s - loss: 0.7047 - val_loss: 1.0908\n",
            "Epoch 3/50\n",
            " - 2s - loss: 0.4757 - val_loss: 0.8247\n",
            "Epoch 4/50\n",
            " - 2s - loss: 0.3781 - val_loss: 0.6915\n",
            "Epoch 5/50\n",
            " - 2s - loss: 0.3208 - val_loss: 0.5911\n",
            "Epoch 6/50\n",
            " - 2s - loss: 0.2855 - val_loss: 0.5208\n",
            "Epoch 7/50\n",
            " - 2s - loss: 0.2589 - val_loss: 0.4934\n",
            "Epoch 8/50\n",
            " - 2s - loss: 0.2479 - val_loss: 0.4542\n",
            "Epoch 9/50\n",
            " - 2s - loss: 0.2263 - val_loss: 0.4062\n",
            "Epoch 10/50\n",
            " - 2s - loss: 0.2071 - val_loss: 0.3756\n",
            "Epoch 11/50\n",
            " - 2s - loss: 0.1942 - val_loss: 0.3722\n",
            "Epoch 12/50\n",
            " - 2s - loss: 0.1832 - val_loss: 0.3459\n",
            "Epoch 13/50\n",
            " - 2s - loss: 0.1790 - val_loss: 0.3217\n",
            "Epoch 14/50\n",
            " - 2s - loss: 0.1714 - val_loss: 0.3146\n",
            "Epoch 15/50\n",
            " - 2s - loss: 0.1622 - val_loss: 0.3050\n",
            "Epoch 16/50\n",
            " - 2s - loss: 0.1582 - val_loss: 0.3246\n",
            "Epoch 17/50\n",
            " - 2s - loss: 0.1523 - val_loss: 0.2859\n",
            "Epoch 18/50\n",
            " - 2s - loss: 0.1482 - val_loss: 0.2563\n",
            "Epoch 19/50\n",
            " - 2s - loss: 0.1468 - val_loss: 0.2794\n",
            "Epoch 20/50\n",
            " - 2s - loss: 0.1405 - val_loss: 0.2611\n",
            "Epoch 21/50\n",
            " - 2s - loss: 0.1420 - val_loss: 0.2380\n",
            "Epoch 22/50\n",
            " - 2s - loss: 0.1365 - val_loss: 0.2654\n",
            "Epoch 23/50\n",
            " - 2s - loss: 0.1379 - val_loss: 0.2399\n",
            "Epoch 24/50\n",
            " - 2s - loss: 0.1333 - val_loss: 0.2293\n",
            "Epoch 25/50\n",
            " - 2s - loss: 0.1318 - val_loss: 0.2325\n",
            "Epoch 26/50\n",
            " - 2s - loss: 0.1311 - val_loss: 0.2346\n",
            "Epoch 27/50\n",
            " - 2s - loss: 0.1301 - val_loss: 0.2439\n",
            "Epoch 28/50\n",
            " - 2s - loss: 0.1287 - val_loss: 0.2270\n",
            "Epoch 29/50\n",
            " - 2s - loss: 0.1259 - val_loss: 0.2174\n",
            "Epoch 30/50\n",
            " - 2s - loss: 0.1256 - val_loss: 0.1912\n",
            "Epoch 31/50\n",
            " - 2s - loss: 0.1227 - val_loss: 0.2099\n",
            "Epoch 32/50\n",
            " - 2s - loss: 0.1204 - val_loss: 0.2026\n",
            "Epoch 33/50\n",
            " - 2s - loss: 0.1222 - val_loss: 0.2070\n",
            "Epoch 34/50\n",
            " - 2s - loss: 0.1183 - val_loss: 0.2070\n",
            "Epoch 35/50\n",
            " - 2s - loss: 0.1199 - val_loss: 0.1975\n",
            "Epoch 36/50\n",
            " - 2s - loss: 0.1184 - val_loss: 0.1950\n",
            "Epoch 37/50\n",
            " - 2s - loss: 0.1150 - val_loss: 0.1959\n",
            "Epoch 38/50\n",
            " - 2s - loss: 0.1146 - val_loss: 0.1984\n",
            "Epoch 39/50\n",
            " - 2s - loss: 0.1124 - val_loss: 0.1809\n",
            "Epoch 40/50\n",
            " - 2s - loss: 0.1142 - val_loss: 0.1979\n",
            "Epoch 41/50\n",
            " - 2s - loss: 0.1139 - val_loss: 0.1841\n",
            "Epoch 42/50\n",
            " - 2s - loss: 0.1107 - val_loss: 0.1919\n",
            "Epoch 43/50\n",
            " - 2s - loss: 0.1100 - val_loss: 0.1867\n",
            "Epoch 44/50\n",
            " - 2s - loss: 0.1123 - val_loss: 0.1749\n",
            "Epoch 45/50\n",
            " - 2s - loss: 0.1092 - val_loss: 0.1837\n",
            "Epoch 46/50\n",
            " - 2s - loss: 0.1095 - val_loss: 0.1930\n",
            "Epoch 47/50\n",
            " - 2s - loss: 0.1092 - val_loss: 0.1855\n",
            "Epoch 48/50\n",
            " - 2s - loss: 0.1070 - val_loss: 0.1892\n",
            "Epoch 49/50\n",
            " - 2s - loss: 0.1053 - val_loss: 0.1771\n",
            "Epoch 50/50\n",
            " - 2s - loss: 0.1049 - val_loss: 0.1901\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_14 (CuDNNLSTM)    (None, 512)               1054720   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,055,233\n",
            "Trainable params: 1,055,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "LSTM with 3 time delays has 0  -ve predictions\n",
            "Root-mean-squared-log-error for LSTM 0.4251249363698687\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_14 (CuDNNLSTM)    (None, 512)               1054720   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,055,233\n",
            "Trainable params: 1,055,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuJq4gM6x-H5",
        "colab_type": "code",
        "outputId": "76459d7c-5fcd-45cf-fae5-3e55491f2ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        }
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as kr\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class PrintDot(kr.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 10 == 0: print(' ',end='')\n",
        "    if epoch % 50 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "def DataProcess(data,label,timesteps=1):\n",
        "  batch_size=label.size\n",
        "  n_feature=data.shape[1]\n",
        "  data_dim=n_feature+1\n",
        "  label=np.reshape(label,(batch_size,1))\n",
        "  X=np.zeros((batch_size,timesteps,data_dim))\n",
        "  \n",
        "  for i in range(timesteps):\n",
        "    dt=i+1\n",
        "    X[:,i,:]=np.hstack(( np.roll(data,dt,axis=0), np.roll(label,dt,axis=0) ))\n",
        "    \n",
        "  return X[timesteps:,:,:],label[timesteps:]\n",
        "#----------------  \n",
        "timesteps=3\n",
        "\n",
        "X=np.loadtxt(fname='hour.csv',delimiter=',',skiprows=1,usecols=(2,4,5,6,7,8,9,10,11,12,13))\n",
        "y=np.loadtxt(fname='hour.csv',delimiter=',',skiprows=1,usecols=16)\n",
        "data_dim=X.shape[1]+1\n",
        "n_half=math.floor(y.shape[0]/2)\n",
        "\n",
        "X,y=DataProcess(X,y,timesteps)\n",
        "\n",
        "X_trn=X[:n_half];y_trn=y[:n_half]\n",
        "X_val,X_tst,y_val,y_tst=train_test_split(X[n_half+1:],y[n_half+1:],test_size=0.4)\n",
        "\n",
        "#----------------\n",
        "lstm=kr.Sequential()\n",
        "lstm.add(kr.layers.CuDNNGRU(units=512,input_shape=(timesteps,data_dim)))\n",
        "lstm.add(kr.layers.Dense(units=512))\n",
        "lstm.add(kr.layers.Dense(units=1))\n",
        "\n",
        "opt=kr.optimizers.Nadam()\n",
        "rmsle=kr.losses.MeanSquaredLogarithmicError()\n",
        "\n",
        "lstm.compile(loss=rmsle, optimizer=opt)#, metrics=['mean_squared_error'])\n",
        "\n",
        "h=lstm.fit(x=X_trn, y=y_trn, epochs=150, validation_data=(X_val,y_val), verbose=0, callbacks=[PrintDot()], use_multiprocessing=True) #validation_data=(X_val,y_val),\n",
        "\n",
        "plt.plot(h.epoch,np.sqrt(h.history['loss']),'r-')\n",
        "plt.plot(h.epoch,np.sqrt(h.history['val_loss']),'b-')\n",
        "plt.xlabel('Epochs'); plt.ylabel('RMSLE')\n",
        "plt.grid(True)\n",
        "plt.legend(['TrnErr','ValErr'])\n",
        "\n",
        "ValErr_best=np.min(h.history['val_loss'])\n",
        "print(\"\\nThe best result is {}\".format(np.sqrt(ValErr_best)))\n",
        "\n",
        "y_pred_lstm_tst = lstm.predict(X_tst) #[:, :14])\n",
        "\n",
        "y_pred_lstm_tst[ np.where(y_pred_lstm_tst<0) ]=0\n",
        "  #y_pred_etr_val[y_pred_etr_val<0]=0\n",
        "lstm_neg_preds=y_tst.shape[0] - np.count_nonzero(y_pred_lstm_tst)\n",
        "print('LSTM with 3 time delays has',lstm_neg_preds,' -ve predictions')\n",
        "lstm_rmsle=math.sqrt(mean_squared_log_error(y_tst,y_pred_lstm_tst))\n",
        "print('Root-mean-squared-log-error for LSTM',lstm_rmsle)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            " \n",
            ".......... .......... .......... .......... .......... \n",
            ".......... .......... .......... .......... .......... \n",
            ".......... .......... .......... .......... ..........\n",
            "The best result is 0.38285765384145304\n",
            "LSTM with 3 time delays has 0  -ve predictions\n",
            "Root-mean-squared-log-error for LSTM 0.39355774767146834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHxMFwzAMw4+JgmEYhuHHRMEwDMPw8/+aiEINmaHBdgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}